# Zero-shot sketch-based image retrieval

Using a semantic-aware network and a triplet loss along with a domain-classifying adversarial loss with a deep convolutional feature extractor, the problem of retrieving images from a large-database using ambiguous sketches has been addressed. This problem has been addressed in the **zero-shot scenario**, where the test sketches/images are from **unseen classes** and the deep feature extractor's output embedding distances have been used to retrieve the top k closest images from the image database of the unseen classes.

# Results

# Instructions

<details>
<summary>
Data
</summary>
  
[The Sketchy dataset](http://transattr.cs.brown.edu/files/aligned_images.tar) - 1.8 GB

</details>
<details>

<summary>
Training
</summary>

</details>

<details>

<summary>
Inference
</summary>
</details>


